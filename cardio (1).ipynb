{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "!pip install pycaret"
      ],
      "metadata": {
        "id": "asTB-KZQ158D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e755cf-550d-4832-bb59-d8e677365280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting pycaret\n",
            "  Downloading pycaret-3.3.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting category-encoders>=2.4.0 (from pycaret)\n",
            "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[?25l\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir9-Ovo8UhUA",
        "outputId": "572e6d80-5007-41f3-c165-d233512d7cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41FVvLm7KY0p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from termcolor import colored\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "#from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV, cross_validate, train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score, precision_score, confusion_matrix, classification_report, RocCurveDisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cardio=pd.read_csv(\"/content/cardio_train.csv\")"
      ],
      "metadata": {
        "id": "dpp8CPn7K69N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "ce37fc0b-6ce8-4831-9034-b3d4b32b2ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/cardio_train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-05717c211ce8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcardio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/cardio_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/cardio_train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cardio"
      ],
      "metadata": {
        "id": "qMiG2E7OLOIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_data = []\n",
        "\n",
        "# Iterate over each line in the data\n",
        "for line in cardio:\n",
        "    # Split the line by semicolon and strip any whitespace\n",
        "    split_line = [elem.strip() for elem in line.split(';')]\n",
        "    # Add the split line to our data list\n",
        "    split_data.append(split_line)\n",
        "\n",
        "# Convert the list of data into a DataFrame\n",
        "# We are skipping the first row because it contains the column names\n",
        "data_df_manual1 = pd.DataFrame(split_data[1:], columns=split_data[0])\n",
        "\n",
        "# Display the first few entries to verify the DataFrame structure\n",
        "data_df_manual1.head()\n"
      ],
      "metadata": {
        "id": "wJp3iVFjM5iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_data = []\n",
        "expected_num_columns = None\n",
        "\n",
        "# Iterate over each line in the data\n",
        "for index, line in enumerate(cardio['id;age;gender;height;weight;ap_hi;ap_lo;cholesterol;gluc;smoke;alco;active;cardio']):\n",
        "    # Split the line by semicolon and strip any whitespace\n",
        "    split_line = [elem.strip() for elem in line.split(';')]\n",
        "\n",
        "    # Set expected number of columns based on the first line\n",
        "    if index == 0:\n",
        "        expected_num_columns = len(split_line)\n",
        "\n",
        "    # Check if the current line has the expected number of columns\n",
        "    if len(split_line) == expected_num_columns:\n",
        "        split_data.append(split_line)\n",
        "    else:\n",
        "        print(f\"Data format error in line {index}: {line}\")"
      ],
      "metadata": {
        "id": "oOvEoGT7Po5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio = pd.DataFrame(split_data, columns=data_df_manual1.columns)"
      ],
      "metadata": {
        "id": "ZgAo8eAIOMFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio.drop(['id'],inplace=True,axis=1)"
      ],
      "metadata": {
        "id": "_ebJMUpfORmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio['age'] = np.floor(cardio['age'].astype(float) / 365.25).astype(int)"
      ],
      "metadata": {
        "id": "EV0RtiLGOqFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio.info()"
      ],
      "metadata": {
        "id": "G7AO3IvpRCUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio.describe(include='object')"
      ],
      "metadata": {
        "id": "Dq6qVjJ5q6xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio['ap_lo'] = cardio['ap_lo'].astype(int)"
      ],
      "metadata": {
        "id": "0x-jNR-YUEfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio['ap_hi'] = cardio['ap_hi'].astype(int)"
      ],
      "metadata": {
        "id": "VJpH0dtvUAFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio['height'] = cardio['height'].astype(int)"
      ],
      "metadata": {
        "id": "nbOknfTaTGBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio['weight'] = cardio['weight'].astype(float)"
      ],
      "metadata": {
        "id": "u2cTZiCuTgt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio.describe()"
      ],
      "metadata": {
        "id": "sLQ39V6QShRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_nulls(df):\n",
        "  null_counts = {}\n",
        "  for column in df.columns:\n",
        "        count = df[column].isnull().sum()\n",
        "        null_counts[column] = count\n",
        "        print(f\" {column} column : has {count} null value.\")\n",
        "\n",
        "  return null_counts"
      ],
      "metadata": {
        "id": "I3vxgj4QWUKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5\n",
        "X = data_scaled_df.drop(columns=['cardio'])\n",
        "y = data_scaled_df['cardio']\n",
        "# Initialize SelectKBest with mutual information score\n",
        "selector = SelectKBest(score_func=mutual_info_classif, k=k)\n",
        "\n",
        "# Fit selector to training data\n",
        "selector.fit(X, y)\n",
        "\n",
        "# Get selected feature indices\n",
        "selected_indices = selector.get_support(indices=True)\n",
        "\n",
        "# Get names of selected features\n",
        "selected_features = X.columns[selected_indices]\n",
        "\n",
        "print(\"Selected features:\", selected_features)"
      ],
      "metadata": {
        "id": "ByluUpoqlfwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=cardio.drop(['cardio'],axis=1)\n",
        "y=cardio['cardio']\n",
        "mutual_info_scores = mutual_info_classif(x, y)\n",
        "\n",
        "# Create a DataFrame to store feature names and their corresponding scores\n",
        "feature_scores_df = pd.DataFrame({'Feature': x.columns, 'Mutual Information Score': mutual_info_scores})\n",
        "\n",
        "# Sort the DataFrame by mutual information scores in descending order\n",
        "feature_scores_df = feature_scores_df.sort_values(by='Mutual Information Score', ascending=False)"
      ],
      "metadata": {
        "id": "JVJKB-1JqXcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_scores_df"
      ],
      "metadata": {
        "id": "7W4hbf1Xqapy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_info = check_nulls(cardio)"
      ],
      "metadata": {
        "id": "MxBc76bAWbQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#outliers\n",
        "cardio[cardio[\"ap_hi\"]<0]\n",
        "cardio[\"ap_hi\"]=cardio[\"ap_hi\"].abs()\n",
        "cardio[cardio[\"ap_lo\"]<0]\n",
        "cardio[\"ap_lo\"]=cardio[\"ap_lo\"].abs()"
      ],
      "metadata": {
        "id": "k1jZxHwrzBB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_outliers(df):\n",
        "    outlier_indices = {}\n",
        "    for column in df.columns:\n",
        "        if df[column].dtype != 'object':  # Exclude non-numeric columns\n",
        "            # Calculate Q1 (25th percentile) and Q3 (75th percentile) of the column\n",
        "            Q1 = df[column].quantile(0.25)\n",
        "            Q3 = df[column].quantile(0.75)\n",
        "            # Define the Interquartile Range (IQR)\n",
        "            IQR = Q3 - Q1\n",
        "            # Define outlier bounds\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            # Find the outliers\n",
        "            outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "            # Store the indices of the outliers if any\n",
        "            if not outliers.empty:\n",
        "                outlier_indices[column] = outliers.index.tolist()\n",
        "\n",
        "    return outlier_indices"
      ],
      "metadata": {
        "id": "D1n4dX0nQGtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outliers_dict = detect_outliers(cardio)"
      ],
      "metadata": {
        "id": "we-wffTIQMgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def detect_and_plot_outliers(df, columns):\n",
        "    \"\"\"\n",
        "    Detect outliers in specified columns of a DataFrame based on the IQR method and plot the results.\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): The DataFrame to check for outliers.\n",
        "    columns (list): List of column names to check for outliers.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with column names as keys and lists of outlier indices as values.\n",
        "    \"\"\"\n",
        "    outlier_indices = {}\n",
        "\n",
        "    # Set up the matplotlib figure\n",
        "    num_plots = len(columns)\n",
        "    fig, axes = plt.subplots(num_plots, figsize=(10, num_plots * 5))\n",
        "\n",
        "    if num_plots == 1:\n",
        "        axes = [axes]  # Make it iterable\n",
        "\n",
        "    for ax, column in zip(axes, columns):\n",
        "        if column in df.columns and df[column].dtype != 'object':  # Check for non-object column\n",
        "            # Calculate Q1 (25th percentile) and Q3 (75th percentile) of the column\n",
        "            Q1 = df[column].quantile(0.25)\n",
        "            Q3 = df[column].quantile(0.75)\n",
        "            # Define the Interquartile Range (IQR)\n",
        "            IQR = Q3 - Q1\n",
        "            # Define outlier bounds\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            # Find the outliers\n",
        "            outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "            # Store the indices of the outliers if any\n",
        "            if not outliers.empty:\n",
        "                outlier_indices[column] = outliers.index.tolist()\n",
        "\n",
        "            # Plot\n",
        "            sns.boxplot(x=df[column], ax=ax)\n",
        "\n",
        "            # Determine whisker's end locations for better visualization\n",
        "            whisker_props = dict(linestyle='-', linewidth=2, color='blue')\n",
        "            flier_props = dict(marker='o', markersize=5, linestyle='none', markeredgecolor='red')\n",
        "\n",
        "            sns.boxplot(x=df[column], ax=ax, whis=1.5, showfliers=True,\n",
        "                        whiskerprops=whisker_props, flierprops=flier_props)\n",
        "\n",
        "            ax.set_title(f'Outlier Detection in \"{column}\"')\n",
        "            ax.set_xlabel(column)\n",
        "\n",
        "            # Set x-axis to logarithmic scale if the data has a large range\n",
        "            # ax.set_xscale('log')\n",
        "            ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return outlier_indices\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'data_df' is your DataFrame\n",
        "# data_df = pd.DataFrame({\n",
        "#     'A': [1, 2, 3, 4, 100],  # 100 is an outlier\n",
        "#     'B': [10, 20, 30, 40, 50],  # No outliers\n",
        "#     'C': [100, 200, 300, -\n"
      ],
      "metadata": {
        "id": "EkJclflCVp92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outliers_dict = detect_and_plot_outliers(cardio, ['ap_hi','ap_lo','weight','height'])"
      ],
      "metadata": {
        "id": "1LLTh2bpVtq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##REMOVING OUTLIERS\n"
      ],
      "metadata": {
        "id": "iUMmv84gZBxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''def standard_deviation_removal(data, num_std_dev=4):\n",
        "    if data.dtype.kind in 'bifc':  # Checks if the column is numeric\n",
        "        mean = data.mean()\n",
        "        std_dev = data.std()\n",
        "        return data[(data > mean - num_std_dev * std_dev) & (data < mean + num_std_dev * std_dev)]\n",
        "    else:\n",
        "        return data'''"
      ],
      "metadata": {
        "id": "tWFc_0XWVvvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''def quantile_based_removal(data, lower_quantile=0.01, upper_quantile=0.99):\n",
        "    if data.dtype.kind in 'bifc':  # Checks if the column is numeric\n",
        "        qlow = data.quantile(lower_quantile)\n",
        "        qhigh = data.quantile(upper_quantile)\n",
        "        return data[(data > qlow) & (data < qhigh)]\n",
        "    else:\n",
        "        return data'''"
      ],
      "metadata": {
        "id": "FAn_JsRZWvzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''def apply_outlier_methods(df):\n",
        "    # Apply each method to each column and store the result\n",
        "    for method in [quantile_based_removal]:\n",
        "        for column in df.columns:\n",
        "            original_data = df[column]\n",
        "            cleaned_data = method(df[column])\n",
        "            # Report which rows were removed\n",
        "            removed_rows = original_data[~original_data.index.isin(cleaned_data.index)]\n",
        "            if not removed_rows.empty:\n",
        "            # Update the DataFrame column\n",
        "            df[column] = cleaned_data\n",
        "    return df'''"
      ],
      "metadata": {
        "id": "DYoiqT7HWQug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio = apply_outlier_methods(cardio)"
      ],
      "metadata": {
        "id": "QIjZQWDRWZeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio"
      ],
      "metadata": {
        "id": "AzyDU_FJWjft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio.info()"
      ],
      "metadata": {
        "id": "hymckryIZpBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_nan_with_mean(df):\n",
        "    \"\"\"\n",
        "    Fills NaN values in numeric columns of a DataFrame with the mean of each column.\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): The DataFrame to process.\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: The DataFrame with NaN values replaced by mean in numeric columns.\n",
        "    \"\"\"\n",
        "    # Iterate over each column in the DataFrame\n",
        "    for column in df.columns:\n",
        "        # Check if the column is numeric\n",
        "        if df[column].dtype in ['int64', 'float64']:\n",
        "            # Calculate the mean of the column, excluding NaN values\n",
        "            column_mean = df[column].mean()\n",
        "            # Replace NaN values with the mean\n",
        "            df[column].fillna(column_mean, inplace=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "7NiqqfkEaAhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio = fill_nan_with_mean(cardio)"
      ],
      "metadata": {
        "id": "aXfd5E4-aCDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio.info()"
      ],
      "metadata": {
        "id": "LYz0-SvYaHgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio=cardio[cardio['ap_hi'] <= 250]"
      ],
      "metadata": {
        "id": "t2TuDHJeXJ47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio=cardio[cardio['ap_lo'] <= 250]"
      ],
      "metadata": {
        "id": "ncT3DcizXcUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### removing height outlier\n",
        "cardio=cardio[cardio['height'] >= 100]"
      ],
      "metadata": {
        "id": "SfMb4ZIvSEjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio=cardio[cardio['weight'] >= 35]"
      ],
      "metadata": {
        "id": "o7X5pJEbZIvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio=cardio[cardio['weight'] <= 175]"
      ],
      "metadata": {
        "id": "A4-pILMgjZbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio=cardio[cardio['height'] <= 205]"
      ],
      "metadata": {
        "id": "PXz2dqwOcVG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio=cardio[cardio['ap_hi'] >= 25]"
      ],
      "metadata": {
        "id": "eBlRjk1qdK1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio=cardio[cardio['ap_lo'] >= 15]"
      ],
      "metadata": {
        "id": "dPvG8ZV0dSQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outliers_dict = detect_and_plot_outliers(cardio, ['ap_hi','ap_lo','height','weight'])"
      ],
      "metadata": {
        "id": "78IFRlJ6QYiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio=cleaned_data"
      ],
      "metadata": {
        "id": "peEdo7xmXA8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio.describe()"
      ],
      "metadata": {
        "id": "Wn5xLvKrUW9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cor = cardio.corr()\n",
        "plt.figure(figsize=(12, 8))\n",
        "cmap = sns.cubehelix_palette(start=2, rot=0, dark=0, light=.95, reverse=True, as_cmap=True)\n",
        "sns.heatmap(cor, cmap=\"Blues\", annot=True)\n",
        "\n",
        "plt.title('Correlation Heatmap', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V2M7GoP-wbda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = cardio.corr()\n",
        "\n",
        "#We only take the correlations with 'target'.\n",
        "target_correlation = correlation_matrix['cardio'].sort_values(ascending=False)\n",
        "target_correlation = target_correlation.drop(\"cardio\")\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.heatmap(target_correlation.to_frame(), cmap=\"coolwarm\", annot=True, vmin=-1, vmax=1)\n",
        "plt.title(\"Correlations with Target Variable\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OCpjqwJp1XL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_age(df, age_column, bins, labels):\n",
        "  if age_column not in df.columns:\n",
        "        raise ValueError(f\"The column '{age_column}' does not exist in the DataFrame.\")\n",
        "\n",
        "    # Use pd.cut to categorize ages\n",
        "  df['age_category'] = pd.cut(df[age_column], bins=bins, labels=labels,right=False, include_lowest=True)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "pTApxUZCYUHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bins = [18, 30, 40, 50, 60, 101]\n",
        "labels = ['18-29', '30-39', '40-49', '50-59', '60-100']\n",
        "cardio = categorize_age(cardio, 'age', bins, labels)"
      ],
      "metadata": {
        "id": "Hi3Fim-FWjof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio.info()"
      ],
      "metadata": {
        "id": "P9jbuYXaYgUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_bmi_category(df, height_column, weight_column):\n",
        "  df['BMI'] = df[weight_column] / (df[height_column] / 100) ** 2\n",
        "\n",
        "    # Define BMI categories according to common thresholds\n",
        "  conditions = [\n",
        "        (df['BMI'] < 18.5),\n",
        "        (df['BMI'] >= 18.5) & (df['BMI'] < 25),\n",
        "        (df['BMI'] >= 25) & (df['BMI'] < 30),\n",
        "        (df['BMI'] >= 30)\n",
        "    ]\n",
        "  categories = ['Underweight', 'Normal', 'Overweight', 'Obese']\n",
        "\n",
        "    # Use numpy.select to apply the conditions to categories\n",
        "  df['BMI_Category'] = np.select(conditions, categories, default='Unknown')\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "3FEJzUhUg9s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio = add_bmi_category(cardio, 'height', 'weight')"
      ],
      "metadata": {
        "id": "T1XaRugBhZzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio"
      ],
      "metadata": {
        "id": "VvRMQKz0iEiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_blood_pressure(df, sys_column, dia_column):\n",
        "  conditions = [\n",
        "        (df[sys_column] < 120) & (df[dia_column] < 80),\n",
        "        (df[sys_column] >= 120) & (df[sys_column] < 130) & (df[dia_column] < 80),\n",
        "        ((df[sys_column] >= 130) & (df[sys_column] < 140)) | ((df[dia_column] >= 80) & (df[dia_column] < 89)),\n",
        "        (df[sys_column] >= 140) | (df[dia_column] >= 90),\n",
        "        (df[sys_column] > 180) | (df[dia_column] > 120)\n",
        "    ]\n",
        "\n",
        "  categories = [\n",
        "        'Normal',\n",
        "        'Elevated',\n",
        "        'High Blood Pressure (Hypertension) Stage 1',\n",
        "        'High Blood Pressure (Hypertension) Stage 2',\n",
        "        'Hypertensive Crisis'\n",
        "    ]\n",
        "\n",
        "  df['BP_Category'] = np.select(conditions, categories, default='Unknown')\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "leiOAZXsmzkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio = categorize_blood_pressure(cardio, 'ap_hi', 'ap_lo')"
      ],
      "metadata": {
        "id": "0Ilx64v0nBLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio['BP_Category'].value_counts()"
      ],
      "metadata": {
        "id": "ozLD3tRDnY8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio"
      ],
      "metadata": {
        "id": "5N6zXcJToeiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
        "\n",
        "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
        "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and dataframe[col].dtypes != \"O\"]\n",
        "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and dataframe[col].dtypes == \"O\"]\n",
        "    cat_cols = cat_cols + num_but_cat\n",
        "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
        "\n",
        "\n",
        "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
        "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
        "\n",
        "    print(f\"Observations: {dataframe.shape[0]}\")\n",
        "    print(f\"Variables: {dataframe.shape[1]}\")\n",
        "    print(f'cat_cols: {len(cat_cols)}')\n",
        "    print(f'num_cols: {len(num_cols)}')\n",
        "    print(f'cat_but_car: {len(cat_but_car)}')\n",
        "    print(f'num_but_cat: {len(num_but_cat)}')\n",
        "\n",
        "    return cat_cols, num_cols, cat_but_car"
      ],
      "metadata": {
        "id": "cx-f2Z7LrwXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols, num_cols, cat_but_car = grab_col_names(cardio)\n",
        "print(f\"\\n{colored('Numerical Columns:','blue', attrs=['reverse'])} {num_cols}\\n\\n\\n{colored('Categorical Columns:','magenta', attrs=['reverse'])} {cat_cols}\\n\\n\\n\"\n",
        "        f\"{colored('Cardinal Columns:','cyan', attrs=['reverse'])}{cat_but_car}\\n\")"
      ],
      "metadata": {
        "id": "sG_cnmXIr9LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cat_summary(dataframe, col_name, plot=False):\n",
        "    display(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n",
        "                        \"Ratio\": 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n",
        "\n",
        "    if plot:\n",
        "        sns.countplot(x=dataframe[col_name], data=dataframe)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "hjaQTzQ3pWNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cat_cols:\n",
        "    cat_summary(cardio, col)"
      ],
      "metadata": {
        "id": "Xj6bIXXFrUK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_summary(dataframe, numerical_col, plot=False):\n",
        "    if plot:\n",
        "        dataframe[numerical_col].hist(bins=200)\n",
        "        plt.xlabel(numerical_col)\n",
        "        plt.title(numerical_col)\n",
        "        plt.show(block=True)"
      ],
      "metadata": {
        "id": "cGHcuZPotDjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in num_cols:\n",
        "    num_summary(cardio, col, True)"
      ],
      "metadata": {
        "id": "slFfZmTRtNe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio"
      ],
      "metadata": {
        "id": "bhSRrnHiXUGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dcPoFtr-Yo6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio.info()"
      ],
      "metadata": {
        "id": "e-o7UyysYpAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_categorical_to_onehot(df):\n",
        "    \"\"\"\n",
        "    Converts all categorical columns in the dataframe to one-hot encoded columns.\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): The DataFrame containing the data.\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: A DataFrame with original non-categorical columns and added one-hot encoded columns.\n",
        "    \"\"\"\n",
        "    # Identify categorical columns (assume categorical columns are of type 'object' or 'category')\n",
        "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "    # If there are no categorical columns, just return the original DataFrame\n",
        "    if not categorical_cols.tolist():\n",
        "        return df\n",
        "\n",
        "    # Initialize the OneHotEncoder\n",
        "    ohe = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "    # Apply OneHotEncoder to categorical columns\n",
        "    ohe_result = ohe.fit_transform(df[categorical_cols])\n",
        "\n",
        "    # Convert the result to a DataFrame with appropriate column names\n",
        "    ohe_df = pd.DataFrame(ohe_result.toarray(), columns=ohe.get_feature_names_out(categorical_cols), index=df.index)\n",
        "\n",
        "    # Debugging: Check the shapes to see if they match\n",
        "    print(f\"Shape of OHE result array: {ohe_result.shape}\")\n",
        "    print(f\"Number of OHE column names: {len(ohe.get_feature_names_out(categorical_cols))}\")\n",
        "\n",
        "    # Drop original categorical columns and concatenate the OHE DataFrame\n",
        "    df_dropped = df.drop(columns=categorical_cols)\n",
        "    df_encoded = pd.concat([df_dropped, ohe_df], axis=1)\n",
        "\n",
        "    return df_encoded\n"
      ],
      "metadata": {
        "id": "JSIuV7FBuQgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=cardio.drop('cardio',axis=1)"
      ],
      "metadata": {
        "id": "ziIz4C5KvYUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot = convert_categorical_to_onehot(x)"
      ],
      "metadata": {
        "id": "A88hJFLNvJmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot"
      ],
      "metadata": {
        "id": "fL6WuQQfkbce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "EFCmJH0Dn3hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardio.shape"
      ],
      "metadata": {
        "id": "knRlnRbVcZlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot.shape"
      ],
      "metadata": {
        "id": "NoAQ7jz6cZBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(onehot, cardio['cardio'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "bxV0DSE5s_Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot"
      ],
      "metadata": {
        "id": "wQE0iz6OlJ6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "# Fit the scaler to the data and transform it\n",
        "#scaled_features = scaler.fit_transform(onehot)\n",
        "# Convert the scaled data back to a DataFrame for readability\n",
        "#scaled_onehot = pd.DataFrame(scaled_features, columns=onehot.columns)\n",
        "scaler.fit(X_train)\n",
        "x_train=scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "CiOV4UfifRVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC(kernel='linear')"
      ],
      "metadata": {
        "id": "pA2YKK-stlru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "zFGc2HLwtvF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test data\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "clf_report = classification_report(y_test, y_pred)"
      ],
      "metadata": {
        "id": "O3HFWHDwz-f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v=list(y_pred)"
      ],
      "metadata": {
        "id": "VvzQdet-hpZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(v)"
      ],
      "metadata": {
        "id": "SsfUqmfDkq-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "tIjPgKX0lBPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ydata_profiling"
      ],
      "metadata": {
        "id": "F0_p3WhOxSJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "profile = ProfileReport(scaled_onehot, title=\"Pandas Profiling Report\")\n",
        "profile"
      ],
      "metadata": {
        "id": "zJvnhPdovzkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_onehot.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "d8Etm0BBx2Me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df"
      ],
      "metadata": {
        "id": "Y4g-bK2dx7wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycaret"
      ],
      "metadata": {
        "id": "pSM4htFE1u6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_onehot['target'] = y"
      ],
      "metadata": {
        "id": "ViIfBN6Rlrm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_onehot"
      ],
      "metadata": {
        "id": "K116hOlylyu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.classification import *\n",
        "s = setup(scaled_onehot,target='target', train_size = 0.8, fold = 3)"
      ],
      "metadata": {
        "id": "zHdWCl8N-M-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best = compare_models()"
      ],
      "metadata": {
        "id": "30Ym4oZUl-Kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "id": "23oMLm_a7-KL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_df\n",
        "y = cardio['cardio']"
      ],
      "metadata": {
        "id": "-StA5Qqr0e3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.info()"
      ],
      "metadata": {
        "id": "Jm6qFVrc84yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_model = LGBMClassifier()"
      ],
      "metadata": {
        "id": "M3-csUvw8Zai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_model_= cross_validate(lgbm_model, data_df, y, cv = 10, scoring = [\"accuracy\", \"f1\", \"roc_auc\"])"
      ],
      "metadata": {
        "id": "EmSQ1ajH8dyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_model_[\"test_accuracy\"].mean()"
      ],
      "metadata": {
        "id": "-CYLhj6Z9YsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7C3fkEa39o__"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}